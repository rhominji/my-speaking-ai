<script>
	import { user } from '$lib/auth.js';
	import { saveConversation } from '$lib/conversation.js';

	let mediaRecorder;
	let mediaStream;
	let audioChunks = [];
	let isRecording = false;
	let isPaused = false;
	let recordedUrl = '';
	let recordedBlob;
	let errorMessage = '';
	let elapsedMs = 0;
	let timerId;
	let audioEl;

	let analyser;
	let audioContext;
	let sourceNode;
	let volume = 0; // 0..100
	let rafId;

	// === Realtime(WebRTC) ì´ˆì €ì§€ì—° ===
	let isRealtime = false;
	let pc; // RTCPeerConnection
	let remoteAudioEl; // ì›ê²© ìŒì„± ì¶œë ¥

	// ë””ë²„ê·¸
	let debugOpen = false;
	let debugLogs = [];
	let realtimeError = '';

	// ì—°ê²°/í†µê³„ ìƒíƒœ
	let rtState = { ice: 'new', connection: 'new', signaling: 'stable' };
	let statsTimerId;
	let bytesSentTotal = 0;
	let bytesRecvTotal = 0;
	let prevBytesSent = 0;
	let prevBytesRecv = 0;
	let kbpsUp = 0;
	let kbpsDown = 0;
	let realtimeClosedAt = '';

	function logDebug(step, payload) {
		try {
			debugLogs = [
				{ time: new Date().toISOString(), step, message: typeof payload === 'string' ? payload : JSON.stringify(payload, null, 2) },
				...debugLogs
			].slice(0, 100);
		} catch {
			// noop
		}
	}

	async function debugFetch(url, init) {
		logDebug('fetch:request', { url, ...{ method: init?.method || 'GET' }, headers: init?.headers, body: init?.body instanceof FormData ? 'FormData' : init?.body });
		const res = await fetch(url, init);
		const headers = Array.from(res.headers.entries());
		const text = await res.text();
		logDebug('fetch:response', { url, status: res.status, ok: res.ok, headers, text: text.slice(0, 2000) });
		return { ok: res.ok, status: res.status, headers, text };
	}

	async function startRealtime() {
		if (isRealtime) return;
		await ensureMic();
		realtimeError = '';
		// 1) PeerConnection ìƒì„± (ì´ˆì €ì§€ì—°ì— ìœ ë¦¬í•œ ê¸°ë³¸ ì„¤ì •)
		pc = new RTCPeerConnection({
			iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
		});
		pc.onicecandidate = () => {};
		pc.ontrack = (e) => {
			// ëª¨ë¸ ìŒì„± ì¶œë ¥
			if (!remoteAudioEl) return;
			remoteAudioEl.srcObject = e.streams[0];
			remoteAudioEl.play().catch(() => {});
		};
		pc.oniceconnectionstatechange = () => { rtState.ice = pc.iceConnectionState; };
		pc.onconnectionstatechange = () => { rtState.connection = pc.connectionState; };
		pc.onsignalingstatechange = () => { rtState.signaling = pc.signalingState; };
		// 2) ë¡œì»¬ ë§ˆì´í¬ íŠ¸ë™ ì¶”ê°€
		mediaStream.getTracks().forEach((t) => pc.addTrack(t, mediaStream));
		// 3) ìˆ˜ì‹  ì „ìš© íŠ¸ëœì‹œë²„ë¡œ ì§€ì—° ìµœì†Œí™”
		pc.addTransceiver('audio', { direction: 'recvonly' });
		// 4) SDP offer ìƒì„±
		const offer = await pc.createOffer({ offerToReceiveAudio: true });
		await pc.setLocalDescription(offer);
		// 5) ì„œë²„ì—ì„œ ephemeral í† í° ë°œê¸‰
		const tokenResp = await debugFetch('/api/realtime-token', { method: 'POST' });
		let tokenData = {};
		try { tokenData = JSON.parse(tokenResp.text || '{}'); } catch (e) { logDebug('token:parse:error', String(e)); }
		const ephemeralKey = tokenData.value || tokenData.client_secret || tokenData.token || '';
		if (!tokenResp.ok || !ephemeralKey) {
			realtimeError = `í† í° ë°œê¸‰ ì‹¤íŒ¨(status ${tokenResp.status})`;
			throw new Error('ephemeral í† í° ë°œê¸‰ ì‹¤íŒ¨');
		}
		// 6) OpenAI Realtimeì— SDP ì „ì†¡ í›„ answer ìˆ˜ì‹ 
		const sdpResp = await debugFetch('https://api.openai.com/v1/realtime/calls', {
			method: 'POST',
			body: offer.sdp,
			headers: {
				Authorization: `Bearer ${ephemeralKey}`,
				'Content-Type': 'application/sdp'
			}
		});
		const answerSdp = sdpResp.text;
		await pc.setRemoteDescription({ type: 'answer', sdp: answerSdp });
		isRealtime = true;
		bytesSentTotal = 0; bytesRecvTotal = 0; prevBytesSent = 0; prevBytesRecv = 0; kbpsUp = 0; kbpsDown = 0; realtimeClosedAt = '';
		startStatsPolling();
	}

	async function stopRealtime() {
		if (!pc) return;
		try { pc.getSenders().forEach((s) => { try { s.track && s.track.stop(); } catch {} }); } catch {}
		try { pc.close(); } catch {}
		pc = undefined;
		isRealtime = false;
		rtState.connection = 'closed';
		stopStatsPolling();
		realtimeClosedAt = new Date().toISOString();
		if (remoteAudioEl) { try { remoteAudioEl.srcObject = null; } catch {} }
	}

	function startStatsPolling() {
		stopStatsPolling();
		statsTimerId = setInterval(async () => {
			if (!pc) return;
			try {
				const report = await pc.getStats();
				let sent = 0, recv = 0;
				report.forEach((s) => {
					if (s.type === 'outbound-rtp' && s.kind === 'audio') sent += s.bytesSent || 0;
					if (s.type === 'inbound-rtp' && s.kind === 'audio') recv += s.bytesReceived || 0;
				});
				bytesSentTotal = sent; bytesRecvTotal = recv;
				kbpsUp = Math.max(0, Math.round(((sent - prevBytesSent) * 8) / 1000));
				kbpsDown = Math.max(0, Math.round(((recv - prevBytesRecv) * 8) / 1000));
				prevBytesSent = sent; prevBytesRecv = recv;
			} catch (e) { /* ignore */ }
		}, 1000);
	}

	function stopStatsPolling() {
		if (statsTimerId) clearInterval(statsTimerId);
		statsTimerId = undefined;
		kbpsUp = 0; kbpsDown = 0;
	}

	// waveform canvas
	let canvasEl;
	let ctx;
	let dpr = 1;
	let canvasWidth = 480;
	let canvasHeight = 160;

	async function ensureMic() {
		try {
			if (mediaStream) return mediaStream;
			mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
			setupAnalyser(mediaStream);
			return mediaStream;
		} catch (err) {
			errorMessage = 'ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.';
			throw err;
		}
	}

	function setupAnalyser(stream) {
		cleanupAnalyser();
		try {
			audioContext = new (window.AudioContext || window.webkitAudioContext)();
			sourceNode = audioContext.createMediaStreamSource(stream);
			analyser = audioContext.createAnalyser();
			analyser.fftSize = 2048;
			sourceNode.connect(analyser);
			loopLevel();
		} catch {
			// ë¶„ì„ê¸°ëŠ” ì„ íƒ ì‚¬í•­ì´ë¯€ë¡œ ì—ëŸ¬ ë¬´ì‹œ
		}
	}

	function loopLevel() {
		if (!analyser) return;
		const bufferLength = analyser.fftSize;
		const timeArray = new Uint8Array(bufferLength);
		const freqArray = new Uint8Array(analyser.frequencyBinCount);
		const tick = () => {
			// level (RMS) ê³„ì‚°
			analyser.getByteTimeDomainData(timeArray);
			let sum = 0;
			for (let i = 0; i < bufferLength; i++) {
				const v = (timeArray[i] - 128) / 128; // -1..1
				sum += v * v;
			}
			const rms = Math.sqrt(sum / bufferLength);
			volume = Math.min(100, Math.max(0, Math.round(rms * 140)));

			// íŒŒí˜• ë§‰ëŒ€ ë Œë”ë§
			if (ctx && canvasEl) {
				analyser.getByteFrequencyData(freqArray);
				ctx.clearRect(0, 0, canvasWidth * dpr, canvasHeight * dpr);
				ctx.fillStyle = '#0b1020';
				ctx.fillRect(0, 0, canvasWidth * dpr, canvasHeight * dpr);
				const bars = 48; // ë§‰ëŒ€ ê°œìˆ˜
				const gap = 4 * dpr;
				const barWidth = ((canvasWidth * dpr) - gap * (bars - 1)) / bars;
				for (let i = 0; i < bars; i++) {
					const idx = Math.floor((i / bars) * freqArray.length);
					const value = freqArray[idx] / 255; // 0..1
					const h = Math.max(4 * dpr, value * canvasHeight * dpr);
					const x = i * (barWidth + gap);
					const y = (canvasHeight * dpr) - h;
					ctx.fillStyle = '#3b82f6';
					ctx.fillRect(x, y, barWidth, h);
				}
			}
			rafId = requestAnimationFrame(tick);
		};
		tick();
	}

	function cleanupAnalyser() {
		if (rafId) cancelAnimationFrame(rafId);
		rafId = undefined;
		try { sourceNode && sourceNode.disconnect(); } catch {}
		try { analyser && analyser.disconnect(); } catch {}
		try { audioContext && audioContext.close(); } catch {}
		sourceNode = undefined;
		analyser = undefined;
		audioContext = undefined;
	}

	function clearTimer() {
		if (timerId) clearInterval(timerId);
		timerId = undefined;
	}

	function startTimer() {
		clearTimer();
		const startAt = Date.now() - elapsedMs;
		timerId = setInterval(() => {
			elapsedMs = Date.now() - startAt;
		}, 100);
	}

	async function startRecording() {
		if (isRecording) return;
		errorMessage = '';
		await ensureMic();
		audioChunks = [];
		recordedUrl && URL.revokeObjectURL(recordedUrl);
		recordedUrl = '';
		recordedBlob = undefined;
		mediaRecorder = new MediaRecorder(mediaStream);
		mediaRecorder.ondataavailable = (e) => {
			if (e.data && e.data.size > 0) audioChunks.push(e.data);
		};
		mediaRecorder.onstop = () => {
			if (audioChunks.length) {
				recordedBlob = new Blob(audioChunks, { type: 'audio/webm' });
				recordedUrl = URL.createObjectURL(recordedBlob);
			}
		};
		mediaRecorder.start();
		isRecording = true;
		isPaused = false;
		elapsedMs = 0;
		startTimer();
	}

	function pauseOrResume() {
		if (!isRecording || !mediaRecorder) return;
		if (!isPaused) {
			mediaRecorder.pause();
			isPaused = true;
			clearTimer();
		} else {
			mediaRecorder.resume();
			isPaused = false;
			startTimer();
		}
	}

	function stopRecording() {
		if (!isRecording || !mediaRecorder) return;
		mediaRecorder.stop();
		isRecording = false;
		isPaused = false;
		clearTimer();
	}

	function resetRecording() {
		stopRecording();
		audioChunks = [];
		recordedBlob = undefined;
		if (recordedUrl) URL.revokeObjectURL(recordedUrl);
		recordedUrl = '';
		elapsedMs = 0;
		errorMessage = '';
	}

	function downloadRecording() {
		if (!recordedBlob) return;
		const a = document.createElement('a');
		const url = recordedUrl || URL.createObjectURL(recordedBlob);
		a.href = url;
		a.download = `recording-${new Date().toISOString().replace(/[:.]/g, '-')}.webm`;
		a.click();
	}

	// === STT/LLM/TTS ì²´ì¸ ì—°ë™ ===
	let transcribedText = '';
	let assistantReply = '';
	let replyAudioUrl = '';
	
	// ëŒ€í™” ê¸°ë¡ ëˆ„ì  ì €ì¥
	let conversationHistory = [];
	let isSessionActive = false;
	let currentTab = 'current'; // 'current' or 'history'
	
	function startNewSession() {
		conversationHistory = [];
		isSessionActive = true;
	}

	async function sendToStt() {
		if (!recordedBlob) return;
		const fd = new FormData();
		fd.append('audio', recordedBlob, 'recording.webm');
		const r = await fetch('/api/stt', { method: 'POST', body: fd });
		const data = await r.json();
		transcribedText = data.text || '';
	}

	async function askLlm() {
		if (!transcribedText) return;
		const r = await fetch('https://api.openai.com/v1/chat/completions', {
			method: 'POST',
			headers: {
				'Content-Type': 'application/json',
				Authorization: `Bearer ${import.meta.env.VITE_OPENAI_PROXY_KEY ?? ''}`
			},
			body: JSON.stringify({
				model: 'gpt-4o-mini',
				messages: [
					{ role: 'system', content: 'You are an English conversation partner. Keep answers concise.' },
					{ role: 'user', content: transcribedText }
				]
			})
		});
		if (!r.ok) { assistantReply = ''; return; }
		const data = await r.json();
		assistantReply = data.choices?.[0]?.message?.content ?? '';
		
		// ëŒ€í™” ê¸°ë¡ ì €ì¥ ë° ëˆ„ì 
		if ($user && transcribedText && assistantReply) {
			await saveConversation($user.id, transcribedText, assistantReply);
			
			// ì„¸ì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ì‹œì‘
			if (!isSessionActive) {
				isSessionActive = true;
			}
			
			// ë¡œì»¬ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
			conversationHistory = [
				...conversationHistory,
				{
					userMessage: transcribedText,
					assistantReply: assistantReply,
					timestamp: new Date().toISOString()
				}
			];
		}
	}
	
	function formatTime(dateString) {
		const date = new Date(dateString);
		return date.toLocaleTimeString('ko-KR', {
			hour: '2-digit',
			minute: '2-digit',
			second: '2-digit'
		});
	}

	async function ttsReply() {
		if (!assistantReply) return;
		const r = await fetch('/api/tts', { method: 'POST', body: JSON.stringify({ text: assistantReply }) });
		const buf = await r.arrayBuffer();
		if (replyAudioUrl) URL.revokeObjectURL(replyAudioUrl);
		replyAudioUrl = URL.createObjectURL(new Blob([buf], { type: 'audio/mpeg' }));
	}

	function fmt(ms) {
		const sec = Math.floor(ms / 1000);
		const m = String(Math.floor(sec / 60)).padStart(2, '0');
		const s = String(sec % 60).padStart(2, '0');
		return `${m}:${s}`;
	}

	function onDestroy() {
		clearTimer();
		cleanupAnalyser();
		try { mediaRecorder && mediaRecorder.stop(); } catch {}
		try { mediaStream && mediaStream.getTracks().forEach((t) => t.stop()); } catch {}
		if (recordedUrl) URL.revokeObjectURL(recordedUrl);
	}

	function ensureCanvas() {
		if (!canvasEl) return;
		dpr = Math.max(1, Math.min(2, window.devicePixelRatio || 1));
		ctx = canvasEl.getContext('2d');
		canvasWidth = Math.min(520, Math.max(320, Math.floor(window.innerWidth - 64)));
		canvasHeight = 160;
		canvasEl.width = canvasWidth * dpr;
		canvasEl.height = canvasHeight * dpr;
		canvasEl.style.width = canvasWidth + 'px';
		canvasEl.style.height = canvasHeight + 'px';
	}
</script>

<main class="container">
	<header class="header">
		<h1>ğŸ™ï¸ ì‹¤ì‹œê°„ ì˜ì–´íšŒí™” AI</h1>
		<p class="subtitle">openai Realtime APIë¡œ ì‹¤ì‹œê°„ ì˜ì–´íšŒí™” AI ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</p>
	</header>

	<!-- ì„¸ì…˜ ìƒíƒœ ë° ìƒˆ ì„¸ì…˜ ì‹œì‘ -->
	<div class="session-controls">
		<div class="session-status">
			<span class="status-indicator {isSessionActive ? 'active' : 'inactive'}"></span>
			<span class="status-text">{isSessionActive ? 'ì„¸ì…˜ í™œì„±' : 'ì„¸ì…˜ ë¹„í™œì„±'}</span>
		</div>
		<button class="new-session-btn" on:click={startNewSession}>ìƒˆ ì„¸ì…˜ ì‹œì‘</button>
	</div>

	<!-- ë…¹ìŒ ì•„ì´ì½˜ -->
	<div class="recording-section">
		<div class="mic-icon-wrapper">
			<div class="mic-icon {isRecording ? 'recording' : ''}">
				<svg width="48" height="48" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
					<path d="M12 14a3 3 0 0 0 3-3V6a3 3 0 1 0-6 0v5a3 3 0 0 0 3 3Z" fill="currentColor"/>
					<path d="M5 11a1 1 0 1 0-2 0 9 9 0 0 0 8 8v3h2v-3a9 9 0 0 0 8-8 1 1 0 1 0-2 0 7 7 0 0 1-14 0Z" fill="currentColor"/>
				</svg>
			</div>
			{#if isRecording}
				<div class="recording-status">ë…¹ìŒ ì¤‘... {fmt(elapsedMs)}</div>
			{/if}
		</div>
	</div>

	<!-- ì—°ê²° ì—¬ë¶€ -->
	<div class="connection-status">
		<div class="rt-status">
			<div>ì—°ê²°: {rtState.connection} â€¢ ICE: {rtState.ice} â€¢ ì‹ í˜¸: {rtState.signaling}</div>
			<div>ì—…/ë‹¤ìš´ ëŒ€ì—­í­: {kbpsUp} / {kbpsDown} kbps</div>
			<div>ëˆ„ì  ë°”ì´íŠ¸: â†‘ {bytesSentTotal}B, â†“ {bytesRecvTotal}B {#if realtimeClosedAt}(ì¢…ë£Œ: {realtimeClosedAt}){/if}</div>
			{#if !isRealtime && rtState.connection === 'closed' && kbpsUp === 0 && kbpsDown === 0}
				<div class="ok">ì‹¤ì‹œê°„ ì„¸ì…˜ì´ ì™„ì „íˆ ì¢…ë£Œë˜ì—ˆê³  ì „ì†¡ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.</div>
			{/if}
		</div>
		{#if realtimeError}
			<p class="error">{realtimeError}</p>
		{/if}
	</div>

	<!-- AI ëŒ€í™” ì‹œì‘ ë²„íŠ¼ê³¼ ë””ë²„ê·¸ ë²„íŠ¼ -->
	<div class="action-buttons">
		{#if !isRecording}
			<button class="ai-chat-btn" on:click={async () => { await ensureMic(); startRecording(); ensureCanvas(); }}>
				AI ëŒ€í™” ì‹œì‘
			</button>
		{:else}
			<button class="ai-chat-btn stop-btn" on:click={stopRecording}>
				ë…¹ìŒ ì¤‘ì§€
			</button>
		{/if}
		<button class="debug-btn" on:click={() => debugOpen = !debugOpen}>
			{debugOpen ? 'ë””ë²„ê·¸ ë‹«ê¸°' : 'ë””ë²„ê·¸ ì—´ê¸°'}
		</button>
	</div>

	<!-- ë””ë²„ê·¸ íŒ¨ë„ -->
	{#if debugOpen}
		<div class="debug-panel">
			<ul class="log">
				{#each debugLogs as l}
					<li>
						<div class="log-head">[{l.time}] {l.step}</div>
						<pre>{l.message}</pre>
					</li>
				{/each}
			</ul>
		</div>
	{/if}

	<!-- íƒ­ -->
	<div class="tabs">
		<button class="tab-btn {currentTab === 'current' ? 'active' : ''}" on:click={() => currentTab = 'current'}>
			í˜„ì¬ ëŒ€í™”
		</button>
		<button class="tab-btn {currentTab === 'history' ? 'active' : ''}" on:click={() => currentTab = 'history'}>
			ëŒ€í™” ê¸°ë¡
		</button>
	</div>

	<!-- íƒ­ ì»¨í…ì¸  -->
	<div class="tab-content">
		{#if currentTab === 'current'}
			<!-- í˜„ì¬ ëŒ€í™” íƒ­ -->
			<div class="current-conversation">
				{#if recordedUrl}
					<div class="playback">
						<audio bind:this={audioEl} src={recordedUrl} controls></audio>
						<div class="playback-actions">
							<button on:click={sendToStt}>ì „ì‚¬(STT)</button>
							<button on:click={async () => { await sendToStt(); await askLlm(); await ttsReply(); }}>ì§ˆë¬¸â†’ì‘ë‹µ(TTS)</button>
							<button on:click={resetRecording}>ë‹¤ì‹œ ë…¹ìŒ</button>
							<button class="primary" on:click={downloadRecording}>ë‹¤ìš´ë¡œë“œ</button>
						</div>
						{#if replyAudioUrl}
							<audio src={replyAudioUrl} controls style="margin-top: 12px;"></audio>
						{/if}
					</div>
				{/if}
				
				{#if conversationHistory.length > 0}
					<div class="conversation-list">
						{#each conversationHistory as conversation (conversation.timestamp)}
							<div class="conversation-item">
								<div class="conversation-time">{formatTime(conversation.timestamp)}</div>
								<div class="user-message">
									<div class="message-label">ë‚˜</div>
									<div class="message-content">{conversation.userMessage}</div>
								</div>
								<div class="assistant-message">
									<div class="message-label">AI</div>
									<div class="message-content">{conversation.assistantReply}</div>
								</div>
							</div>
						{/each}
					</div>
				{:else}
					<div class="empty-state">
						<p>ì•„ì§ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. AI ëŒ€í™” ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.</p>
					</div>
				{/if}
			</div>
		{:else}
			<!-- ëŒ€í™” ê¸°ë¡ íƒ­ -->
			<div class="history-tab">
				{#if conversationHistory.length > 0}
					<div class="conversation-list">
						{#each conversationHistory as conversation (conversation.timestamp)}
							<div class="conversation-item">
								<div class="conversation-time">{formatTime(conversation.timestamp)}</div>
								<div class="user-message">
									<div class="message-label">ë‚˜</div>
									<div class="message-content">{conversation.userMessage}</div>
								</div>
								<div class="assistant-message">
									<div class="message-label">AI</div>
									<div class="message-content">{conversation.assistantReply}</div>
								</div>
							</div>
						{/each}
					</div>
				{:else}
					<div class="empty-state">
						<p>ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.</p>
					</div>
				{/if}
			</div>
		{/if}
	</div>

	<!-- ìˆ¨ê²¨ì§„ ì˜¤ë””ì˜¤ ìš”ì†Œ -->
	<audio bind:this={remoteAudioEl} autoplay style="display: none;"></audio>

	{#if errorMessage}
		<p class="error">{errorMessage}</p>
	{/if}
</main>

<svelte:window on:resize={ensureCanvas} on:load={ensureCanvas} />

<style>
	.container {
		min-height: 100vh;
		padding: 40px 16px;
		background: radial-gradient(1200px 600px at 20% -10%, #e8f0ff, transparent),
			radial-gradient(1200px 600px at 120% 110%, #e8f0ff, transparent);
		max-width: 900px;
		margin: 0 auto;
	}

	.header {
		text-align: center;
		margin-bottom: 24px;
	}

	.header h1 {
		font-size: 32px;
		margin: 0 0 6px;
		color: #0f172a;
	}

	.subtitle {
		color: #475569;
		margin: 0;
	}

	/* ì„¸ì…˜ ì»¨íŠ¸ë¡¤ */
	.session-controls {
		display: flex;
		justify-content: space-between;
		align-items: center;
		max-width: 720px;
		margin: 0 auto 24px;
		padding: 16px;
		background: white;
		border: 1px solid #e5e7eb;
		border-radius: 12px;
		box-shadow: 0 1px 2px rgba(0, 0, 0, 0.04);
	}

	.session-status {
		display: flex;
		align-items: center;
		gap: 8px;
	}

	.status-indicator {
		width: 12px;
		height: 12px;
		border-radius: 50%;
		display: inline-block;
	}

	.status-indicator.active {
		background: #10b981;
		box-shadow: 0 0 8px rgba(16, 185, 129, 0.5);
	}

	.status-indicator.inactive {
		background: #94a3b8;
	}

	.status-text {
		font-size: 14px;
		font-weight: 600;
		color: #334155;
	}

	.new-session-btn {
		padding: 8px 16px;
		background: #2563eb;
		color: white;
		border: none;
		border-radius: 8px;
		font-size: 14px;
		font-weight: 600;
		cursor: pointer;
		transition: background 0.2s;
	}

	.new-session-btn:hover {
		background: #1d4ed8;
	}

	/* ë…¹ìŒ ì„¹ì…˜ */
	.recording-section {
		display: flex;
		justify-content: center;
		margin-bottom: 24px;
	}

	.mic-icon-wrapper {
		display: flex;
		flex-direction: column;
		align-items: center;
		gap: 12px;
	}

	.mic-icon {
		width: 80px;
		height: 80px;
		border-radius: 50%;
		background: #e5e7eb;
		display: flex;
		align-items: center;
		justify-content: center;
		color: #64748b;
		transition: all 0.3s;
	}

	.mic-icon.recording {
		background: #fee2e2;
		color: #b91c1c;
		animation: pulse 1.5s ease-in-out infinite;
	}

	@keyframes pulse {
		0%, 100% { transform: scale(1); }
		50% { transform: scale(1.1); }
	}

	.recording-status {
		font-size: 14px;
		font-weight: 600;
		color: #b91c1c;
	}

	/* ì—°ê²° ìƒíƒœ */
	.connection-status {
		max-width: 720px;
		margin: 0 auto 24px;
		padding: 16px;
		background: white;
		border: 1px solid #e5e7eb;
		border-radius: 12px;
		box-shadow: 0 1px 2px rgba(0, 0, 0, 0.04);
	}

	.rt-status {
		font-size: 12px;
		color: #334155;
		display: grid;
		gap: 4px;
	}

	.rt-status .ok {
		color: #15803d;
		margin-top: 8px;
	}

	.error {
		color: #b91c1c;
		margin-top: 8px;
		font-size: 14px;
	}

	/* ì•¡ì…˜ ë²„íŠ¼ */
	.action-buttons {
		display: flex;
		justify-content: center;
		gap: 12px;
		margin-bottom: 24px;
	}

	.ai-chat-btn {
		padding: 12px 24px;
		background: #0f172a;
		color: white;
		border: none;
		border-radius: 8px;
		font-size: 16px;
		font-weight: 700;
		cursor: pointer;
		transition: background 0.2s;
	}

	.ai-chat-btn:hover {
		background: #1e293b;
	}

	.ai-chat-btn.stop-btn {
		background: #b91c1c;
	}

	.ai-chat-btn.stop-btn:hover {
		background: #991b1b;
	}

	.debug-btn {
		padding: 12px 24px;
		background: #f9fafb;
		color: #334155;
		border: 1px solid #d1d5db;
		border-radius: 8px;
		font-size: 14px;
		font-weight: 600;
		cursor: pointer;
		transition: background 0.2s;
	}

	.debug-btn:hover {
		background: #f3f4f6;
	}

	/* ë””ë²„ê·¸ íŒ¨ë„ */
	.debug-panel {
		max-width: 920px;
		margin: 0 auto 24px;
		padding: 16px;
		background: #0b1020;
		border-radius: 12px;
		max-height: 400px;
		overflow-y: auto;
	}

	.log {
		list-style: none;
		padding: 0;
		margin: 0;
		display: grid;
		gap: 8px;
	}

	.log-head {
		font-weight: 700;
		color: #e2e8f0;
		margin-bottom: 4px;
	}

	pre {
		background: #1e293b;
		color: #e2e8f0;
		padding: 8px;
		border-radius: 8px;
		overflow: auto;
		font-size: 12px;
	}

	/* íƒ­ */
	.tabs {
		display: flex;
		justify-content: center;
		gap: 8px;
		margin-bottom: 24px;
		max-width: 720px;
		margin-left: auto;
		margin-right: auto;
	}

	.tab-btn {
		flex: 1;
		padding: 12px 24px;
		background: white;
		color: #64748b;
		border: 1px solid #e5e7eb;
		border-radius: 8px 8px 0 0;
		font-size: 14px;
		font-weight: 600;
		cursor: pointer;
		transition: all 0.2s;
	}

	.tab-btn.active {
		background: #f9fafb;
		color: #0f172a;
		border-bottom-color: transparent;
	}

	.tab-btn:hover:not(.active) {
		background: #f3f4f6;
	}

	/* íƒ­ ì»¨í…ì¸  */
	.tab-content {
		max-width: 720px;
		margin: 0 auto;
		padding: 24px;
		background: white;
		border: 1px solid #e5e7eb;
		border-radius: 0 0 12px 12px;
		box-shadow: 0 1px 2px rgba(0, 0, 0, 0.04);
		min-height: 400px;
		max-height: 600px;
		overflow-y: auto;
	}

	.playback {
		margin-bottom: 24px;
		text-align: center;
	}

	.playback audio {
		width: 100%;
		margin-bottom: 12px;
	}

	.playback-actions {
		display: flex;
		gap: 8px;
		justify-content: center;
		flex-wrap: wrap;
	}

	.playback-actions button {
		padding: 8px 12px;
		background: #f9fafb;
		border: 1px solid #d1d5db;
		border-radius: 8px;
		font-size: 14px;
		cursor: pointer;
		transition: background 0.2s;
	}

	.playback-actions button:hover {
		background: #f3f4f6;
	}

	.playback-actions button.primary {
		background: #2563eb;
		color: white;
		border-color: #2563eb;
	}

	.playback-actions button.primary:hover {
		background: #1d4ed8;
	}

	/* ëŒ€í™” ëª©ë¡ */
	.conversation-list {
		display: flex;
		flex-direction: column;
		gap: 20px;
	}

	.conversation-item {
		display: flex;
		flex-direction: column;
		gap: 12px;
		padding-bottom: 20px;
		border-bottom: 1px solid #f1f5f9;
	}

	.conversation-item:last-child {
		border-bottom: none;
		padding-bottom: 0;
	}

	.conversation-time {
		font-size: 12px;
		color: #94a3b8;
		font-weight: 600;
		margin-bottom: 4px;
	}

	.user-message,
	.assistant-message {
		display: flex;
		gap: 12px;
		align-items: flex-start;
	}

	.message-label {
		font-weight: 700;
		font-size: 12px;
		padding: 6px 10px;
		border-radius: 6px;
		white-space: nowrap;
		min-width: 40px;
		text-align: center;
	}

	.user-message .message-label {
		background: #dbeafe;
		color: #1e40af;
	}

	.assistant-message .message-label {
		background: #f3e8ff;
		color: #6b21a8;
	}

	.message-content {
		flex: 1;
		padding: 12px 16px;
		border-radius: 8px;
		color: #334155;
		line-height: 1.6;
		word-wrap: break-word;
	}

	.user-message .message-content {
		background: #eff6ff;
	}

	.assistant-message .message-content {
		background: #faf5ff;
	}

	/* ë¹ˆ ìƒíƒœ */
	.empty-state {
		text-align: center;
		padding: 60px 20px;
		color: #64748b;
	}

	.empty-state p {
		margin: 0;
		font-size: 14px;
	}
</style>
